{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [Your Project Name]: [Brief Description]\n",
        "\n",
        "This notebook demonstrates [your project/algorithm/method] and compares it with [baseline method] on [dataset/task].\n",
        "\n",
        "## What is [Your Project Name]?\n",
        "\n",
        "[Your Project Name] extends [existing method] with [your innovation]:\n",
        "\n",
        "1. **[Feature 1]**: [Description of first key feature]\n",
        "2. **[Feature 2]**: [Description of second key feature]\n",
        "3. **[Feature 3]**: [Description of third key feature]\n",
        "\n",
        "**Key Benefits:**\n",
        "- [Benefit 1]: [Quantified improvement or qualitative benefit]\n",
        "- [Benefit 2]: [Quantified improvement or qualitative benefit]\n",
        "- [Benefit 3]: [Quantified improvement or qualitative benefit]\n",
        "- [Benefit 4]: [Quantified improvement or qualitative benefit]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install your package\n",
        "! [ -d \"template\" ] && git clone https://github.com/username/template.git\n",
        "! cd template && pip install -e .\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change to your project directory if needed\n",
        "import os\n",
        "\n",
        "os.chdir(\"./template\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "# Set device (adapt for your framework)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [Your Method] vs [Baseline Method]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constants for demo limits (adjust based on your needs)\n",
        "MAX_TRAINING_BATCHES = 50\n",
        "MAX_EVAL_SAMPLES = 1000\n",
        "NUM_EPOCHS = 3\n",
        "\n",
        "# Quick demo - simplified version for notebook\n",
        "def quick_demo():\n",
        "    print(\"[Your Method] Demo - Comparing with [Baseline Method]\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\"Training for {NUM_EPOCHS} epochs...\")\n",
        "\n",
        "    # Train both models\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "\n",
        "    # Evaluate\n",
        "    def evaluate_model(model, testloader, model_name=\"Model\"):\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            eval_pbar = tqdm(testloader, desc=f\"Evaluating {model_name}\", leave=False)\n",
        "\n",
        "            for data, target in eval_pbar:\n",
        "                if total >= MAX_EVAL_SAMPLES:\n",
        "                    break\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "                eval_pbar.set_postfix({\"acc\": f\"{100 * correct / total:.2f}%\"})\n",
        "\n",
        "        return 100 * correct / total\n",
        "\n",
        "    print(\"Demo completed!\")\n",
        "\n",
        "\n",
        "# Run the demo\n",
        "quick_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "This demo shows how [Your Method] works:\n",
        "\n",
        "1. **[Key Feature 1]**: [Description of how your method works]\n",
        "2. **[Key Feature 2]**: [Description of integration with existing methods]\n",
        "3. **[Key Feature 3]**: [Description of performance benefits]\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try the full training script: `python -m scripts.train --config configs/your_config.yaml`\n",
        "- Experiment with different hyperparameters ([param1], [param2])\n",
        "- Check out the [full paper/documentation](https://your-link.com) for detailed results\n",
        "\n",
        "For more information, visit the [GitHub repository](https://github.com/yourusername/yourrepo)."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
